SRC_DIR = os.path.abspath(os.path.join(this_dir, "src"))
N_BAM_READS_CHECK=1000
samps = pd.read_csv(value)
samps
exp = samps.experiment[0]
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samps['file_type'] = samptype
samps
eff_gen_size=pd.read_table(GENSIZE_PATH)
samptype == "public"
samps['paired_end'] = [bam_info(bam, N_BAM_READS_CHECK)['paired_end'] for bam in samps['experiment']]
samps['read_length'] = [bam_info(bam, N_BAM_READS_CHECK)['read_len'] for bam in samps['experiment']]
samps['run'] = [os.path.abspath(bam) for bam in samps['experiment']]
samps['name'] = samps['experiment'] = [os.path.splitext(os.path.basename(exp))[0] for exp in samps['experiment']]
samps
samps['control']=""
sizes=eff_gen_size['read_length'].unique()
[min(sizes, key=lambda x:abs(x-sizeCheck)) for sizeCheck in samps['read_length']]
samps['read_length'] = [min(sizes, key=lambda x:abs(x-sizeCheck)) for sizeCheck in samps['read_length']]
samps
pd.merge(samps, eff_gen_size.rename(columns={"UCSC_orgID": "genome"}), how='inner')
samps
samps._get_cleaned_column_resolvers
samps['genom']
samps['genome']
samps = pd.read_csv(value)
{'a': 1, 'b': 2}
aa={'a': 1, 'b': 2}
del aa['a']
aa
value = "rseq_out_bams"
os.path.exists(value)
os.path.exsts(os.path.join(value, "config.json"))
os.path.join(value, "config.json")
os.path.exists(os.path.join(value, "config.json"))
os.path.exists(value) and os.path.exists(os.path.join(value, "config.json"))
import importlib
__file__=("../../rseq/cli.py")
path = os.path.abspath(__file__)
path
dir_path = os.path.dirname(path)
dir_path
path
path = __file__
path
find_module('rseqcli')
value
value = "tests/test_data/fq_test_samples_1.csv"
samps = pd.read_csv(value)
samps
exp = samps.experiment[0]
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
redict
samptype = [key for key, val in redict.items() if re.match(val, exp)]
value
samps.experiment
samps.experiment[1]
redict = {
"fastq": "^.+\\.f[ast]q$|^.+\\.f[ast]q\\~.+\\.f[ast]q$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
exp = samps.experiment[0]
exp
redict = {
"fastq": "^.+\\.f[ast]q$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
"fastq": "^.+\\.fq$",
redict = {
"fastq": "^.+\\.fq$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
exp
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samptype
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
redict = {
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samptype
samps["file_type"] = samptype
samps
controls = False
samps["control"] = ""
samps["run"] = [os.path.abspath(bam) for bam in samps["experiment"]]
samps
samps["name"] = samps["experiment"] = [
os.path.splitext(os.path.basename(exp))[0] for exp in samps["experiment"]
]
samps
samps
re.match("\\~", exp)
[re.match("\\~", exp) for exp in samps["experiment"]]
exp
samps["experiment"]
samps = pd.read_csv(value)
# First, check for matching pattern
# First, check for matching pattern
exp = samps.experiment[0]
redict = {
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samps["file_type"] = samptype
samps
[re.match("~", exp) for exp in samps["experiment"]]
[re.match("\\~", exp) for exp in samps["experiment"]]
[print(exp) for exp in samps["experiment"]]
[bool(re.match("\\~", exp)) for exp in samps["experiment"]]
[bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
samps["paired_end"] = [bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
import pyfastx
pyfastx.Fastx(exp)
fq = pyfastx.Fastx(exp)
[ print(seq) for seq in fq.head() ]
fq.mean
fq
[print(seq) for seq in fq]
fq[1]
fq.__dir__()
fq.__init__
fq.__new__()
fq.__iter__
fq.__iter__()
fq.__iter__().mean
fq.mean()
fq.__getattribute__
fq.__getattribute__()
len(fq)
import pyfastx
len(fq)
fq
exp
fq = pyfastx.Fastx(exp)
len(fq)
fq = pyfastx.Fastq(exp)
fq
fq.mean
fq.mean()
fq.avglen
[
pyfastx.Fastq(exp).avglen for exp in samps["experiment"]
]
[
re.sub(pattern, '\\~.+', exp ) for exp in samps["experiment"]
]
[
re.sub('\\~.+', "", exp ) for exp in samps["experiment"]
]
[
pyfastx.Fastq(re.sub('\\~.+', "", exp )).avglen for exp in samps["experiment"]
]
samps["paired_end"] = [bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
samps["read_length"] = [
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ))).avglen for exp in samps["experiment"]
]
samps["read_length"] = [
round(pyfastx.Fastq(re.sub('\\~.+', "", exp )).avglen) for exp in samps["experiment"]
]
samps["read_length"]
[
os.path.splitext(os.path.basename(re.sub('\\~.+', "", exp )))[0] for exp in samps["experiment"]
]
[
re.sub(
'_[1-2]{1}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)
)[0] for exp in samps["experiment"]
]
[
re.sub(
'_[1-2]{1}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
samps["name"] = [
re.sub(
'_[1-2]{1}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
controls
[
re.sub(
'[\\._]{1}[R1-2]{1-2}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
samps["experiment"]
[
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps["experiment"]
samps
samps.columns
fq = samps['experiment'][0]
fq
[print(fq) for fq in samps[["experiment", "paired_end"]]]
samps[["experiment", "paired_end"]]
samps[["experiment", "paired_end"]].itertuples
[print(fq) for fq in samps[["experiment", "paired_end"]].itertuples]
[print(fq) for fq in samps[["experiment", "paired_end"]].itertuples()]
[print(fq + pe) for fq, pe in samps[["experiment", "paired_end"]].itertuples()]
[enumerate(row) for row in samps[["experiment", "paired_end"]].itertuples()]
[print(key) for key, val in enumerate(row) for row in samps[["experiment", "paired_end"]].itertuples()]
[[print(key) for key, val in enumerate(row)] for row in samps[["experiment", "paired_end"]].itertuples()]
[[print(val) for key, val in enumerate(row)] for row in samps[["experiment", "paired_end"]].itertuples()]
[print(row) for row in samps[["experiment", "paired_end"]].itertuples()]
[print(exp) for idx, exp, pe in samps[["experiment", "paired_end"]].itertuples()]
fq
fq = samps['experiment'][1]
fq
re.sub('\\~.+', "", fq)
fq1=os.path.abspath(re.sub('\\~.+', "", fq))
fq1
fq2=os.path.abspath(re.sub('.+\\~', "", fq))
fq2
fq
fq[-2]
fq[-4]
fq[-4] = 2
fq1+"~"+fq2
[get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
def get_fq_path(fq, pe):
if pe:
fq1=os.path.abspath(re.sub('\\~.+', "", fq))
fq2=os.path.abspath(re.sub('.+\\~', "", fq))
return fq1 + "~" + fq2
else:
return os.path.abspath(fq)
[get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
samps["run"] = [get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
samps["experiment"] = samps["name"]
samps
samps = pd.read_csv(value)
exp = samps.experiment[0]
redict = {
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samps["file_type"] = samptype
samps
controls = False
samps["control"] = ""
# Check which are paired-end
samps["paired_end"] = [bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
samps["read_length"] = [
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps["name"] = [
re.sub(
'[\\._]{1}[R1-2]{1-2}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
samps
samps["experiment"]
[
re.sub(
'[\\._]{1}[R1-2]+$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
controls
samps["control"] = ""
def get_fq_path(fq, pe):
if pe:
fq1=os.path.abspath(re.sub('\\~.+', "", fq))
fq2=os.path.abspath(re.sub('.+\\~', "", fq))
return fq1 + "~" + fq2
else:
return os.path.abspath(fq)
samps["run"] = [get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
samps
samps["experiment"] = samps["name"]
View(samps)
[
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps = pd.read_csv(value)
# First, check for matching pattern
exp = samps.experiment[0]
redict = {
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samps["file_type"] = samptype
samps["control"] = ""
s
samps["paired_end"] = [bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
[
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps["experiment"]
exp = samps["experiment"][2]
re.sub('\\~.+', "", exp )
pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False)
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen)
pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=True)
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=True).avglen)
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen)
URL <- paste0("https://rmapdb-data.s3.us-east-2.amazonaws.com/bigwigs/",
"rseq-coverage-unstranded/SRX1025890_hg38.bw")
devtools::load_all(".")
peaks=RSeqR::SRX1025890_peaks
coverage=URL
genome="hg38"
sampleName="User-supplied Sample"
outputFile = "RSeqR_Report.html"
message("[1] RLFS Perm Test...")
rlfsRes <- analyzeRLFS(peaks=peaks, genome=genome)
message("[2] Predict Condition...")
pred <- predictCondition(rlfsRes = rlfsRes)
message("[3] Feature Enrichment Test...")
featTest <- featureEnrich(peaks=peaks, genome=genome)
message("[4] Correlation Analysis...")
if (! is.null(coverage)) {
if (genome == "hg38") {
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
} else {
warning("Only hg38 is currently available for correlation analysis. Skipping...")
corrRes <- NA
}
} else {
message("No coverage provided... skipping.")
corrRes <- NA
}
message("[4] Correlation Analysis...")
if (! is.null(coverage)) {
if (genome == "hg38") {
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
} else {
warning("Only hg38 is currently available for correlation analysis. Skipping...")
corrRes <- NA
}
} else {
message("No coverage provided... skipping.")
corrRes <- NA
}
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
coverage
URL="https://rmapdb-data.s3.us-east-2.amazonaws.com/coverage/SRX1025890_hg38.bw"
>
URL="https://rmapdb-data.s3.us-east-2.amazonaws.com/coverage/SRX1025890_hg38.bw"
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
URL
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
coverage
coverage <- URL
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
corrRes
annoGenes <- geneAnnotation(peaks, genome = genome)
rlRegions <- rlRegionTest(peaks, genome=genome)
resLst <- list(
"rlfsRes" = rlfsRes,
"predictedCondition" = pred,
"featureTest" = featTest,
"corrRes" = corrRes,
"annoGenes" = annoGenes,
"RLoopRegions" = rlRegions,
"sampleName" = sampleName,
"genome" = genome
)
params <- resLst
# Add params as environmental variables
list2env(params, envir = environment())
params
resLst
params <- resLst
list2env(params, envir = environment())
sample_name
sampleName
mode_now
modes <- readxl::read_excel("../RMapDB-Datasets/rmap-data/RMapDB_manifest_27082021.small.xlsx", sheet = 3)
modes
usethis::use_data(modes)
mode
genome
current_time
RSeqR::rmapSamps
rownames(corrRes)
RSeqR::rmapSamps
library(magrittr)
library(rlang)
tibble::as_tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
tibble::as_tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
tibble::as_tibble(
id = rownames(corrRes)
)
corrRes
tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
# Make static correlation picture
# From: https://stackoverflow.com/questions/31677923/set-0-point-for-pheatmap-in-r
paletteLength <- 100
myColor <- colorRampPalette(rev(
RColorBrewer::brewer.pal(n = 7, name = "RdBu")))(paletteLength)
# length(breaks) == length(paletteLength) + 1
# use floor and ceiling to deal with even/odd length pallettelengths
myBreaks <- c(seq(min(corMat), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corMat)/paletteLength, max(corMat), length.out=floor(paletteLength/2)))
# length(breaks) == length(paletteLength) + 1
# use floor and ceiling to deal with even/odd length pallettelengths
myBreaks <- c(seq(min(corrRes), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corrRes)/paletteLength, max(corrRes), length.out=floor(paletteLength/2)))
tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB"))
anno <- tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(
group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB")
) %>%
dplyr::select(mode, group)
anno
anno <- tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(
group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB")
) %>%
dplyr::select(id, mode, group) %>%
tibble::column_to_rownames("id")
anno
# Make static correlation picture
# From: https://stackoverflow.com/questions/31677923/set-0-point-for-pheatmap-in-r
paletteLength <- 100
paletteLength <- 100
myColor <- colorRampPalette(
rev(RColorBrewer::brewer.pal(n = 7, name = "RdBu"))
)(paletteLength)
myBreaks <- c(seq(min(corrRes), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corrRes)/paletteLength, max(corrRes), length.out=floor(paletteLength/2)))
myBreaks
annodf <- tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(
group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB")
) %>%
dplyr::select(id, mode, group) %>%
tibble::column_to_rownames("id")
# Make static correlation picture
# From: https://stackoverflow.com/questions/31677923/set-0-point-for-pheatmap-in-r
paletteLength <- 100
myColor <- colorRampPalette(
rev(RColorBrewer::brewer.pal(n = 7, name = "RdBu"))
)(paletteLength)
# length(breaks) == length(paletteLength) + 1
# use floor and ceiling to deal with even/odd length pallettelengths
myBreaks <- c(seq(min(corrRes), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corrRes)/paletteLength, max(corrRes), length.out=floor(paletteLength/2)))
pheatmap::pheatmap(corrRes, show_rownames = FALSE,
show_colnames = FALSE,
annotation_colors = list(
Source = c("RMapDB" = "grey", "User-supplied" = "firebrick")
),
color = myColor, breaks = myBreaks,
annotation_col = annodf)
rmapSamples
RSeqR::rmapSamps
library(RLSeq)
