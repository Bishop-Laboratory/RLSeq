]
[
re.sub(
'_[1-2]{1}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
samps["name"] = [
re.sub(
'_[1-2]{1}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
controls
[
re.sub(
'[\\._]{1}[R1-2]{1-2}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
samps["experiment"]
[
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps["experiment"]
samps
samps.columns
fq = samps['experiment'][0]
fq
[print(fq) for fq in samps[["experiment", "paired_end"]]]
samps[["experiment", "paired_end"]]
samps[["experiment", "paired_end"]].itertuples
[print(fq) for fq in samps[["experiment", "paired_end"]].itertuples]
[print(fq) for fq in samps[["experiment", "paired_end"]].itertuples()]
[print(fq + pe) for fq, pe in samps[["experiment", "paired_end"]].itertuples()]
[enumerate(row) for row in samps[["experiment", "paired_end"]].itertuples()]
[print(key) for key, val in enumerate(row) for row in samps[["experiment", "paired_end"]].itertuples()]
[[print(key) for key, val in enumerate(row)] for row in samps[["experiment", "paired_end"]].itertuples()]
[[print(val) for key, val in enumerate(row)] for row in samps[["experiment", "paired_end"]].itertuples()]
[print(row) for row in samps[["experiment", "paired_end"]].itertuples()]
[print(exp) for idx, exp, pe in samps[["experiment", "paired_end"]].itertuples()]
fq
fq = samps['experiment'][1]
fq
re.sub('\\~.+', "", fq)
fq1=os.path.abspath(re.sub('\\~.+', "", fq))
fq1
fq2=os.path.abspath(re.sub('.+\\~', "", fq))
fq2
fq
fq[-2]
fq[-4]
fq[-4] = 2
fq1+"~"+fq2
[get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
def get_fq_path(fq, pe):
if pe:
fq1=os.path.abspath(re.sub('\\~.+', "", fq))
fq2=os.path.abspath(re.sub('.+\\~', "", fq))
return fq1 + "~" + fq2
else:
return os.path.abspath(fq)
[get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
samps["run"] = [get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
samps["experiment"] = samps["name"]
samps
samps = pd.read_csv(value)
exp = samps.experiment[0]
redict = {
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samps["file_type"] = samptype
samps
controls = False
samps["control"] = ""
# Check which are paired-end
samps["paired_end"] = [bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
samps["read_length"] = [
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps["name"] = [
re.sub(
'[\\._]{1}[R1-2]{1-2}$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
samps
samps["experiment"]
[
re.sub(
'[\\._]{1}[R1-2]+$', "", os.path.splitext(
os.path.basename(
re.sub('\\~.+', "", exp )
)
)[0]
) for exp in samps["experiment"]
]
controls
samps["control"] = ""
def get_fq_path(fq, pe):
if pe:
fq1=os.path.abspath(re.sub('\\~.+', "", fq))
fq2=os.path.abspath(re.sub('.+\\~', "", fq))
return fq1 + "~" + fq2
else:
return os.path.abspath(fq)
samps["run"] = [get_fq_path(fq, pe) for idx, fq, pe in samps[["experiment", "paired_end"]].itertuples()]
samps
samps["experiment"] = samps["name"]
View(samps)
[
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps = pd.read_csv(value)
# First, check for matching pattern
exp = samps.experiment[0]
redict = {
"fastq": "^.+\\.[fastq]+$|^.+\\.f[ast]q\\~.+\\.[fastq]+$",
"bam": "^.+\\.bam$",
"public": "^GSM[0-9]+$|^SRX[0-9]+$",
}
samptype = [key for key, val in redict.items() if re.match(val, exp)][0]
samps["file_type"] = samptype
samps["control"] = ""
s
samps["paired_end"] = [bool(re.match(".+\\~.+", exp)) for exp in samps["experiment"]]
[
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen) for exp in samps["experiment"]
]
samps["experiment"]
exp = samps["experiment"][2]
re.sub('\\~.+', "", exp )
pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False)
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen)
pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=True)
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=True).avglen)
round(pyfastx.Fastq(re.sub('\\~.+', "", exp ), build_index=False).avglen)
URL <- paste0("https://rmapdb-data.s3.us-east-2.amazonaws.com/bigwigs/",
"rseq-coverage-unstranded/SRX1025890_hg38.bw")
devtools::load_all(".")
peaks=RSeqR::SRX1025890_peaks
coverage=URL
genome="hg38"
sampleName="User-supplied Sample"
outputFile = "RSeqR_Report.html"
message("[1] RLFS Perm Test...")
rlfsRes <- analyzeRLFS(peaks=peaks, genome=genome)
message("[2] Predict Condition...")
pred <- predictCondition(rlfsRes = rlfsRes)
message("[3] Feature Enrichment Test...")
featTest <- featureEnrich(peaks=peaks, genome=genome)
message("[4] Correlation Analysis...")
if (! is.null(coverage)) {
if (genome == "hg38") {
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
} else {
warning("Only hg38 is currently available for correlation analysis. Skipping...")
corrRes <- NA
}
} else {
message("No coverage provided... skipping.")
corrRes <- NA
}
message("[4] Correlation Analysis...")
if (! is.null(coverage)) {
if (genome == "hg38") {
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
} else {
warning("Only hg38 is currently available for correlation analysis. Skipping...")
corrRes <- NA
}
} else {
message("No coverage provided... skipping.")
corrRes <- NA
}
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
coverage
URL="https://rmapdb-data.s3.us-east-2.amazonaws.com/coverage/SRX1025890_hg38.bw"
>
URL="https://rmapdb-data.s3.us-east-2.amazonaws.com/coverage/SRX1025890_hg38.bw"
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
URL
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
coverage
coverage <- URL
corrRes <- corrAnalyze(coverage=coverage, genome = genome)
corrRes
annoGenes <- geneAnnotation(peaks, genome = genome)
rlRegions <- rlRegionTest(peaks, genome=genome)
resLst <- list(
"rlfsRes" = rlfsRes,
"predictedCondition" = pred,
"featureTest" = featTest,
"corrRes" = corrRes,
"annoGenes" = annoGenes,
"RLoopRegions" = rlRegions,
"sampleName" = sampleName,
"genome" = genome
)
params <- resLst
# Add params as environmental variables
list2env(params, envir = environment())
params
resLst
params <- resLst
list2env(params, envir = environment())
sample_name
sampleName
mode_now
modes <- readxl::read_excel("../RMapDB-Datasets/rmap-data/RMapDB_manifest_27082021.small.xlsx", sheet = 3)
modes
usethis::use_data(modes)
mode
genome
current_time
RSeqR::rmapSamps
rownames(corrRes)
RSeqR::rmapSamps
library(magrittr)
library(rlang)
tibble::as_tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
tibble::as_tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
tibble::as_tibble(
id = rownames(corrRes)
)
corrRes
tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
# Make static correlation picture
# From: https://stackoverflow.com/questions/31677923/set-0-point-for-pheatmap-in-r
paletteLength <- 100
myColor <- colorRampPalette(rev(
RColorBrewer::brewer.pal(n = 7, name = "RdBu")))(paletteLength)
# length(breaks) == length(paletteLength) + 1
# use floor and ceiling to deal with even/odd length pallettelengths
myBreaks <- c(seq(min(corMat), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corMat)/paletteLength, max(corMat), length.out=floor(paletteLength/2)))
# length(breaks) == length(paletteLength) + 1
# use floor and ceiling to deal with even/odd length pallettelengths
myBreaks <- c(seq(min(corrRes), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corrRes)/paletteLength, max(corrRes), length.out=floor(paletteLength/2)))
tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id")
tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB"))
anno <- tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(
group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB")
) %>%
dplyr::select(mode, group)
anno
anno <- tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(
group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB")
) %>%
dplyr::select(id, mode, group) %>%
tibble::column_to_rownames("id")
anno
# Make static correlation picture
# From: https://stackoverflow.com/questions/31677923/set-0-point-for-pheatmap-in-r
paletteLength <- 100
paletteLength <- 100
myColor <- colorRampPalette(
rev(RColorBrewer::brewer.pal(n = 7, name = "RdBu"))
)(paletteLength)
myBreaks <- c(seq(min(corrRes), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corrRes)/paletteLength, max(corrRes), length.out=floor(paletteLength/2)))
myBreaks
annodf <- tibble::tibble(
id = rownames(corrRes)
) %>%
dplyr::left_join(RSeqR::rmapSamps, by = "id") %>%
dplyr::mutate(
group=ifelse(id == "user_supplied", {{  sampleName  }}, "RMapDB")
) %>%
dplyr::select(id, mode, group) %>%
tibble::column_to_rownames("id")
# Make static correlation picture
# From: https://stackoverflow.com/questions/31677923/set-0-point-for-pheatmap-in-r
paletteLength <- 100
myColor <- colorRampPalette(
rev(RColorBrewer::brewer.pal(n = 7, name = "RdBu"))
)(paletteLength)
# length(breaks) == length(paletteLength) + 1
# use floor and ceiling to deal with even/odd length pallettelengths
myBreaks <- c(seq(min(corrRes), 0, length.out=ceiling(paletteLength/2) + 1),
seq(max(corrRes)/paletteLength, max(corrRes), length.out=floor(paletteLength/2)))
pheatmap::pheatmap(corrRes, show_rownames = FALSE,
show_colnames = FALSE,
annotation_colors = list(
Source = c("RMapDB" = "grey", "User-supplied" = "firebrick")
),
color = myColor, breaks = myBreaks,
annotation_col = annodf)
rmapSamples
RSeqR::rmapSamps
library(RLSeq)
library(RLSeq)
RLFS_BED_URL
library(RLSeq)
RLFS_BED_URL
RLSeq:::RLFS_BED_URL
paste0(RLSeq:::RLFS_BED_URL, "hg38", ".rlfs.bed")
readr::read_tsv(paste0(RLSeq:::RLFS_BED_URL, "hg38", ".rlfs.bed"))
urlExists(paste0(RLFS_BED_URL, genome, ".rlfs.bed"))
urlExists <- function(url) {
identical(
httr::status_code(
# Checks HEAD only due to size constraints
httr::HEAD(
url
)
), 200L  # Checks if response is ok
)
}
urlExists(paste0(RLSeq:::RLFS_BED_URL, "hg38", ".rlfs.bed"))
#' Check if URL exists
#' @param url URL to check
#' @return logical. TRUE if status code 200, FALSE if not
urlExists <- function(url) {
identical(
httr::status_code(
# Checks HEAD only due to size constraints
httr::HEAD(
url
)
), 200L  # Checks if response is ok
)
}
#' Get Chrom Sizes
#' Helper function which downloads chrom sizes from UCSC for a genome.
#' @param genome the UCSC genome for which to download chrom sizes
#' @return A tibble containing chrom sizes
#' @importFrom utils capture.output
getChromSizes <- function(genome) {
chrom_sizes <- readr::read_tsv(paste0(
BASE_UCSC,
genome, '/bigZips/', genome, '.chrom.sizes'
), col_names = FALSE, show_col_types = FALSE, progress = FALSE)
return(chrom_sizes)
}
#' Check RLFS Anno
#' Helper function that checks whether a genome has RLFS available
#' @param genome the UCSC genome name to check
#' @return A logical, TRUE if available, FALSE if not
checkRLFSAnno <- function(genome) {
return(
urlExists(paste0(RLFS_BED_URL, genome, ".rlfs.bed"))
)
}
#' Get RLFS Anno
#' Helper function that retrieves RLFS
#' @param genome the UCSC genome name to retrieve RLFS for
#' @return A GRanges object with RLFS for that species.
#' @importFrom utils capture.output
getRLFSAnno <- function(genome) {
# Check if annotations available first
if (! checkRLFSAnno(genome)) {
stop("No RLFS annotations available for ", genome)
}
# Read in RLFS
tsvRLFS <- readr::read_tsv(
paste0(RLFS_BED_URL, genome, ".rlfs.bed"),
col_names = FALSE, show_col_types = FALSE, progress = FALSE
)
# Return as a GRanges object
return(regioneR::toGRanges(as.data.frame(tsvRLFS)))
}
#' Get Chain
#' Helper function that retrieves chain file for liftUtil()
#' @param genomeFrom the UCSC genome name to convert from.
#' @param genomeTo the UCSC genome name to convert to.
#' @importFrom utils download.file
getChain <- function(genomeFrom, genomeTo) {
# Get URL
url <- paste0(BASE_UCSC, genomeFrom, "/liftOver/",
genomeFrom, "To",
paste0(toupper(substring(genomeTo, 1, 1)),
substring(genomeTo, 2)),
".over.chain.gz")
# Check if exists
stopifnot(urlExists(url))
# Check if R.utils available
if( ! requireNamespace("R.utils", quietly = TRUE)) {
stop("R.utils is required. Please install it with install.packages('R.utils')")
}
# Get the chain
tmp <- tempfile()
download.file(url, destfile = paste0(tmp, ".gz"))
R.utils::gunzip(paste0(tmp, ".gz"))
chain <- rtracklayer::import.chain(tmp)
# Return as a GRanges object
return(
chain
)
}
#' Lift Over Utility
#'
#' Convenience function for converting ranges from between assemblies
#'
#' @param ranges A GRanges object in hg19
#' @param genomeFrom Genome of ranges supplied, in UCSC format (e.g., "hg19")
#' @param genomeTo Genome to convert to (e.g., "hg38")
#' @return A lifted GRanges object
#' @examples
#'
#' hg38Lift(RSeqR::SRX1025890_peaks_hg19)
#'
#' @export
liftUtil <- function(ranges, genomeFrom, genomeTo) {
# Get the chain
chain <- getChain(genomeFrom, genomeTo)
# Make sure names exist
if (is.null(names(ranges))) {
names(ranges) <- seq(GenomicRanges::start(ranges))
}
# Lift Over
lifted <- unlist(rtracklayer::liftOver(ranges, chain = chain))
# Force uniqueness
nms <- duplicated(names(lifted))
lifted <- lifted[nms,]
return(lifted)
}
#' GRanges To Bed
#'
#' Converts a GRanges object to a .bed formatted DataFrame and writes to file if requested
#'
#' @param granges A GRanges object containing DRIP-Seq peaks
#' @param write A boolean determining if the converted DataFrame will be written to a .bed file
#' @param filename A string containing the desired file name if writing to file
#' @return A DataFrame object containing the GRanges content formatted according to .bed standards
#' @importFrom utils write.table
grangesToBed <- function(granges, write = FALSE, filename = NULL) {
df <- as.data.frame(granges)
names(df)[1] <- paste0("#", names(df)[1])
if(write) {
write.table(df, file = paste0(filename, ".bed"), sep = "\t", col.names = NA)
}
return(df)
}
#' Get GS Signal
#'
#' Extract signal around GS R-loop sites
#' @param coverage The path to a .bigWig file (can be a URL)
#' @param genome The UCSC genome ID to use. (Currently, only "hg38" is supported)
#' @return A named list containing the results of correlation analysis.
#' @export
getGSSignal <- function(coverage, genome) {
# Get the locations of the gs sites
positions <- RSeqR::gsSignalRMapDB$location
positions <- tibble::tibble(location = positions) %>%
dplyr::mutate(seqnames = gsub(.data$location, pattern = "(.+)_(.+)_(.+)",
replacement = "\\1"),
start = gsub(.data$location, pattern = "(.+)_(.+)_(.+)",
replacement = "\\2"),
end = gsub(.data$location, pattern = "(.+)_(.+)_(.+)",
replacement = "\\3")) %>%
dplyr::select(-.data$location) %>%
GenomicRanges::makeGRangesFromDataFrame()
# Read in the bigWig file using these locations
bw <- rtracklayer::import(con = rtracklayer::BigWigFile(coverage),
selection = positions)
}
getRLFSAnno("hg38")
RLSeq:::getRLFSAnno("hg38")
coverage <- paste0(RLSeq:::RLBASE_BW_URL, "SRX1025890_hg38.bw")
coverage
BW_FILE <- paste0(RLSeq:::RLBASE_BW_URL, "SRX1025890_hg38.bw")
RLSeq::corrAnalyze(coverage = BW_FILE, genome="hg38")
RLSeq::SRX1025890
expect_null(
RLSeq::makeReport(RLSeq::SRX1025890, outputFile = "report.html")
)
makeReport(RLSeq::SRX1025890, outputFile = "report.html")
RLSeq::makeReport(RLSeq::SRX1025890, outputFile = "report.html")
library(RLSeq)
remove.packages("RSeqR")
library(RLSeq)
